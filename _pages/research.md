---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---

My research lies at the intersection of Information Theory, Probability Theory and Functional Analysis. 
To get to know my views on the (fundamental) connection among the fields you can check out my [thesis](https://infoscience.epfl.ch/record/294547).
Applications of my results range from Learning Theory (see [here](https://ieeexplore.ieee.org/abstract/document/8849834), 
[here](https://ieeexplore.ieee.org/abstract/document/9444402), 
[here](https://ieeexplore.ieee.org/abstract/document/8989057), [here](https://arxiv.org/abs/2001.06399), 
and [here](https://ieeexplore.ieee.org/abstract/document/9174117)), to Probability Theory 
(see [here](https://ieeexplore.ieee.org/abstract/document/9517944), [here](https://arxiv.org/pdf/2303.07245.pdf)) and Estimation Theory (see [here](https://ieeexplore.ieee.org/abstract/document/9517954)
and [here](https://ieeexplore.ieee.org/abstract/document/9834708)).

The work I am most proud of is, at the moment, only available as a [conference paper](https://ieeexplore.ieee.org/abstract/document/9834354) 
(a longer version is on its way). It encapsulates my views in which Information Measures simply are a bridge between spaces of measures
and spaces of functions and therein lies their power. 

My current interests consist of a deeper exploration of the framework I set up during my PhD,
and I am grateful for being able to do so with [Marco Mondelli](http://www.marcomondelli.com).


<h2 class="page__title">Preprints</h2>
<ul>
  <li>"Contraction of Markovian Operators in Orlicz Spaces and Error Bounds for Markov Chain Monte Carlo", <strong> Amedeo Roberto Esposito </strong>, Marco Mondelli, Arxiv Pre-print <a href="https://arxiv.org/abs/2402.11200"> LINK </a> </li>
  <li>"A new approach to adaptive data analysis and learning via maximal leakage", <strong>Amedeo Roberto Esposito</strong>,  Ibrahim Issa, Michael Gastpar, Arxiv Pre-print, <a href="https://arxiv.org/pdf/1903.01777.pdf"> LINK </a></li>
</ul>


<h2 class="page__title">Journals & Conferences</h2>
<ul>
  <li>"Concentration without Independence via Information Measures", <strong>Amedeo Roberto Esposito</strong>, Marco Mondelli,<strong> Accepted for publication in the IEEE Transactions in Information Theory </strong><a href="https://arxiv.org/pdf/2303.07245.pdf "> LINK </a></li>
    <li>"Lower Bounds on the Bayesian Risk via Information Measures", <strong>Amedeo Roberto Esposito</strong>, Adrien Vandenbroucque, Michael Gastpar, <strong> Accepted for publication in the Journal of Machine Learning Research (JMLR) </strong>,  <a href="https://arxiv.org/pdf/2303.12497.pdf"> LINK </a></li>
  <li>"Generalization Error Bounds Via Rényi-, f-Divergences and Maximal Leakage", <strong>Amedeo Roberto Esposito</strong>, Ibrahim Issa, Michael Gastpar, in <em> IEEE Transactions on Information Theory Volume: 67, Issue: 8</em>, <a href="https://ieeexplore.ieee.org/document/9444402"> LINK </a></li>
   <li>"Asymptotically Optimal Generalization Error Bounds for Noisy, Iterative Algorithms", Ibrahim Issa, <strong>Amedeo Roberto Esposito</strong>, Michael Gastpar, <strong> Accepted for presentation at the 2023 Conference on Learning Theory (COLT) </strong>, <a href="https://arxiv.org/pdf/2302.14518.pdf"> LINK </a></li>
   <li>"Concentration without Independence via Information Measures", <strong>Amedeo Roberto Esposito</strong>, Marco Mondelli, <strong> Accepted for presentation at the 2023 IEEE International Symposium on Information Theory (ISIT) </strong>, <a href="https://arxiv.org/pdf/2303.07245.pdf "> LINK </a></li>
    <li>"From Generalisation Error to Transportation-cost Inequalities and Back",  <strong>Amedeo Roberto Esposito</strong>, Michael Gastpar in <em> 2022 IEEE International Symposium on Information Theory (ISIT)</em>, <a href="https://ieeexplore.ieee.org/abstract/document/9834354"> LINK </a></li>
  <li>"On Sibson’s α-Mutual Information", <strong>Amedeo Roberto Esposito</strong>, Adrien Vandenbroucque, Michael Gastpar in <em> 2022 IEEE International Symposium on Information Theory (ISIT)</em>, <a href="https://ieeexplore.ieee.org/abstract/document/9834428"> LINK </a></li>
  <li>"Lower-bounds on the Bayesian Risk in Estimation Procedures via f–Divergences",  Adrien Vandenbroucque, <strong>Amedeo Roberto Esposito</strong>, Michael Gastpar in <em> 2022 IEEE International Symposium on Information Theory (ISIT)</em>, <a href="https://ieeexplore.ieee.org/abstract/document/9834708"> LINK </a></li>
    <li>"Towards a Standard Testing Data Set in Privacy", <strong>Amedeo Roberto Esposito</strong>, in <em> BCS Learning & Development</em>, <a href="https://ucl.scienceopen.com/document_file/30dda6d3-0a2c-4b2e-9fa14c91d736bce3/ScienceOpen/1_Esposito_ODAK22.pdf"> LINK </a></li>
  

  <li>"Lower-bounds on the Bayesian Risk in estimation procedures via Sibson's α-Mutual Information",  <strong>Amedeo Roberto Esposito</strong>, Michael Gastpar in <em> 2021 IEEE International Symposium on Information Theory (ISIT)</em>, <a href="https://ieeexplore.ieee.org/abstract/document/9517954"> LINK </a></li>
   <li>"On conditional Sibson's α-Mutual Information",  <strong>Amedeo Roberto Esposito</strong>, Diyuan Wu, Michael Gastpar in <em> 2021 IEEE International Symposium on Information Theory (ISIT)</em>, <a href="https://ieeexplore.ieee.org/abstract/document/9517944"> LINK </a></li>
  
   <li>"Robust Generalization via f−Mutual Information",  <strong>Amedeo Roberto Esposito</strong>, Michael Gastpar, Ibrahim Issa in <em> 2020 IEEE International Symposium on Information Theory (ISIT)</em>, <a href="https://ieeexplore.ieee.org/abstract/document/9174117"> LINK </a></li>
  
   <li>"Robust Generalization via α-Mutual Information",  <strong>Amedeo Roberto Esposito</strong>, Michael Gastpar, Ibrahim Issa in <em> 2020 International Zurich Seminar on Information and Communication</em>, <a href="https://arxiv.org/pdf/2001.06399"> LINK </a></li>
  
   <li>"Learning and adaptive data analysis via maximal leakage",  <strong>Amedeo Roberto Esposito</strong>, Michael Gastpar, Ibrahim Issa in <em> 2019 IEEE Information Theory Workshop (ITW)</em>, <a href="https://ieeexplore.ieee.org/abstract/document/8989057"> LINK </a></li>
  
   <li>"Strengthened information-theoretic bounds on the generalization error",  Ibrahim Issa, <strong>Amedeo Roberto Esposito</strong>, Michael Gastpar in <em> 2019 IEEE International Symposium on Information Theory (ISIT)</em>, <a href="https://ieeexplore.ieee.org/abstract/document/8849834"> LINK </a></li>
</ul>

